# cactus-openai-server
Turn your Android phone into a high-performance OpenAI-compatible API server using Cactus LLM engine. Get 16-75 tok/s local inference with full /v1/chat/completions endpoint.
